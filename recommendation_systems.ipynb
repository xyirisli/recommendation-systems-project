{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "Copy of rs_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAQpYjPVzdsw",
        "colab_type": "text"
      },
      "source": [
        "# Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rWqpOEzdsz",
        "colab_type": "text"
      },
      "source": [
        "### Getting MovieLens data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQaV4DkBzds0",
        "colab_type": "text"
      },
      "source": [
        "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
        "\n",
        "* Upload ml-100k.zip\n",
        "\n",
        "* Extract using the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dHQTK1zds1",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncf3xm1zds2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4aa7c45-8346-47ba-8252-311a222e1c9e"
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import wget\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ill6yOzds5",
        "colab_type": "text"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbQGMevzds8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "50d3f729-4756-474a-83e5-7d94e636c332"
      },
      "source": [
        "wget.download(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOWqsTGzdtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "356f819e-1a02-4d4d-9408-d8ca034d0681"
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0-kPF7zdtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvqWuW5NzdtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RPCAd--22MQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "02fd16e2-e1c4-451b-fef3-bee5b68c79b3"
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpmN2NrTzdtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f432a24c-8fff-4d8a-f61b-d2742c65186c"
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQg7fW9SzdtO",
        "colab_type": "text"
      },
      "source": [
        "## Q1 Data Preprocessing and Baseline algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVaLm25zdtO",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiG_0QfzdtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "    \n",
        "    # Initialize a of size (numUsers, numItems) to zeros\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "    \n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[userID-1, itemID-1] = rating\n",
        "    \n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6DxbgBmzdtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "368bd6be-66d1-4fd7-9f6f-307232402f3e"
      },
      "source": [
        "dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4XZHBczdtU",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9AkrRvUzdtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "        \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        \n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "          # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            if rating == 0:\n",
        "            # select the row for user\n",
        "            # what's the shape of userVector\n",
        "              userVector = train_matrix[user, :]\n",
        "            \n",
        "            # Extract the items the user already rated \n",
        "            ## dimension 1 x num of movies rated, filter out all movies that have been rated\n",
        "              ratedItems = userVector[userVector.nonzero()]\n",
        "            \n",
        "            # If not empty, calculate average and set as rating for the current item\n",
        "              if ratedItems.size == 0:\n",
        "                  itemAvg = 0\n",
        "              else:\n",
        "                  itemAvg = ratedItems.mean()\n",
        "              predictionMatrix[user, item] = itemAvg\n",
        "            \n",
        "          # report progress every 100 users\n",
        "            #if (user % 100 == 0 and item == 1):\n",
        "              #print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        \n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "    \n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
        "        itemPopularity = np.zeros((num_items))\n",
        "        for item in range(num_items):\n",
        "          numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
        "          numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
        "          if numOfUsersRated == 0:\n",
        "             itemPopularity[item] = 0\n",
        "          else:\n",
        "             itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
        "    \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "          # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "          if rating == 0:\n",
        "            predictionMatrix[user, item] = itemPopularity[item]\n",
        "            \n",
        "          # report progress every 100 users\n",
        "          #if (user % 100 == 0 and item == 1):\n",
        "              #print (\"calculated %d users\" % (user,))        \n",
        "                \n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDw3ALnzdtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJd50FSdzdta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "popularity_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5TJkUaszdtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = popularity_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN8r3Obtzdtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2ac0012-bd81-45f7-e16e-02322734d8e6"
      },
      "source": [
        "np.all(x<=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZDsDg5Gzdtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "747433d8-9d3b-4f66-9b38-168ec81adb27"
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p60BEmn-zdtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3c421666-2134-4e1b-c578-9725f51914ea"
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:29, 1117.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  popularity\n",
              "0     196     242       3  881250949         0.0\n",
              "1     186     302       3  891717742         0.0\n",
              "2      22     377       1  878887116         0.0\n",
              "3     244      51       2  880606923         0.0\n",
              "4     166     346       1  886397596         0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDu_THj3zdtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQWmspQGzdtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl8uLyIqzdty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b05a9459-15da-46e9-c682-1acace744e9e"
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 3.61029412, 3.61029412,\n",
              "        3.61029412],\n",
              "       [0.        , 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
              "        3.70967742],\n",
              "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
              "        2.7962963 ],\n",
              "       ...,\n",
              "       [0.        , 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
              "        4.04545455],\n",
              "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
              "        4.26582278],\n",
              "       [3.41071429, 0.        , 3.41071429, ..., 3.41071429, 3.41071429,\n",
              "        3.41071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSCkkxozdt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "835bf193-c787-4c4e-86f4-7d6dc9f4b3cd"
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:28, 1125.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>useraverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  useraverage\n",
              "0     196     242       3  881250949          0.0\n",
              "1     186     302       3  891717742          0.0\n",
              "2      22     377       1  878887116          0.0\n",
              "3     244      51       2  880606923          0.0\n",
              "4     166     346       1  886397596          0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_RlOlrIzdt7",
        "colab_type": "text"
      },
      "source": [
        "## Q2 Similarity in Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4zY0XYDzdt7",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEQ_IkS3zdt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        \n",
        "        \n",
        "        # Euclidean distance = sqrt(sumitem(xi-yi)^2)\n",
        "        # the Euclidean similarity = 1 / (1+euclidean distance), range between [0,1]\n",
        "        # reference: https://stats.stackexchange.com/questions/53068/euclidean-distance-score-and-similarity\n",
        "        \n",
        "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric = 'euclidean'))\n",
        "    \n",
        "        ###########         end         ###########    \n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        \n",
        "        # Manhattan distance is the sum of the lengths of the 'right angle' formed by the two points\n",
        "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric = 'manhattan'))\n",
        "    \n",
        "        ###########         end         ###########        \n",
        "        return similarity_matrix\n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.model\n",
        "            \n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        \n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "             # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = self.method(train_matrix)\n",
        "            \n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            # UxU mul UxI = UxI\n",
        "            \n",
        "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "            #print(predictionMatrix)\n",
        "            \n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average\n",
        "            \n",
        "            ### ??? + 1e-5 or not??\n",
        "            useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1)+1e-5)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            \n",
        "            self.__model = predictionMatrix\n",
        "\n",
        "  \n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "            # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = self.method(train_matrix.transpose())\n",
        "            \n",
        "            # IxU: IxI mul IxU\n",
        "            normalizer = np.matmul(ii_similarity, temp_matrix.transpose())\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            \n",
        "            # IxI mul IxU\n",
        "            predictionMatrix = np.matmul(ii_similarity, train_matrix.transpose())/normalizer\n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no item has been rated by this user before, use item average\n",
        "            \n",
        "            ### ??? + 1e-5 or not?? \n",
        "            itemaverage = np.sum(train_matrix.transpose(), axis=1)/(np.sum(temp_matrix.transpose(), axis=1) +1e-5)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "            \n",
        "            self.__model = predictionMatrix.transpose()\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "            NOTE: 1. data can have more columns, but your function should ignore \n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine', \n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ-CleOotV5q",
        "colab_type": "text"
      },
      "source": [
        "(a) Cosine similarity is better since it is measured by the angle between vectors which would not be affected by the length of the vector whereas the other one concern with the distance which can be affected by vector length significantly. \n",
        "\n",
        "Ref: \n",
        "https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
        "\n",
        "\"The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance because of the size (like, the word ‘cricket’ appeared 50 times in one document and 10 times in another) they could still have a smaller angle between them. Smaller the angle, higher the similarity.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RROHVWRpzduA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "92fa6ab2-fb42-4140-a35f-694db6335efc"
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3)\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ5BkzGPzduC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3d715410-38a7-4d84-f6a2-97ccd297569c"
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.41421356, 0.41421356],\n",
              "       [0.41421356, 1.        , 0.41421356],\n",
              "       [0.41421356, 0.41421356, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V-L-T-PzduF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a17615e-2aa8-4d45-aad1-0a2f2bd9afbc"
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USPsbXpnzduH",
        "colab_type": "text"
      },
      "source": [
        "### (b)\n",
        "\n",
        "Manhattan distance is the total sum of the absolute value of the difference between the x-coordinates and y-coordinates and by taking its inverse we are able to see how far away (or similar) two users or items are, similary to the euclidean similarity. Also, if the dimension of the matrix is high, manhattan distance would work well. \n",
        "\n",
        "Additionally, when you want to place less emphasis on outliers, the manhattan distance will try to reduce all errors equally (as the gradient has constant magnitude).\n",
        "\n",
        "Ref: https://datascience.stackexchange.com/questions/20075/when-would-one-use-manhattan-distance-as-opposite-to-euclidean-distance\n",
        "\n",
        "https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions/99191#99191"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtDt6JLrzduI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDrJogepzduL",
        "colab_type": "text"
      },
      "source": [
        "## Q3 Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ju9mZE9zduM",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAaSIC3BzduM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBGVr2_JzduQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isW4B7nfzduW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cebf63aa-74fd-4816-a397-293ce43f2b6c"
      },
      "source": [
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdxjAZJrzdud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "89eac865-3c4e-4af9-800c-d1bfd3739e4b"
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yc2PgKylzdug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "804a0faa-29bc-4170-fba7-ea015ee725b9"
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:44, 961.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>4.025213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>4.142828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>1.922080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.431884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.424963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  user-cosine\n",
              "0     196     242       3  881250949     4.025213\n",
              "1     186     302       3  891717742     4.142828\n",
              "2      22     377       1  878887116     1.922080\n",
              "3     244      51       2  880606923     3.431884\n",
              "4     166     346       1  886397596     3.424963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ic_FKWUzdui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZdTvp_szduk",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BnXbsLzdul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKyb9l-zdun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to use CrossValidation Class?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU3rZPtnzdus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "#algorithm_instances = [popularity_recsys, \n",
        "                       #average_user_rating_recsys, \n",
        "                       #user_cosine_recsys]\n",
        "\n",
        "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
        "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
        "\n",
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [item_cosine_recsys, \n",
        "                       user_cosine_recsys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-m7d5Dzdux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "cv_patk = CrossValidation('P@K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqcihyZdzduz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "028b562f-4003-4dde-e3e8-e4eaf54ad64e"
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2132.56it/s]\n",
            "20000it [00:09, 2123.47it/s]\n",
            "20000it [00:09, 2102.27it/s]\n",
            "20000it [00:09, 2128.69it/s]\n",
            "20000it [00:10, 1986.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2116.85it/s]\n",
            "20000it [00:09, 2119.20it/s]\n",
            "20000it [00:09, 2118.74it/s]\n",
            "20000it [00:09, 2120.03it/s]\n",
            "20000it [00:09, 2083.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[0.34316012725344736,\n",
              "   0.483563096500532,\n",
              "   0.6021208907741271,\n",
              "   0.6248144220572649,\n",
              "   0.6074231177094392],\n",
              "  0.5322163308589621,\n",
              "  0.3837005215009889,\n",
              "  0.6807321402169354],\n",
              " 'user-cosine': [[0.37179215270413657,\n",
              "   0.503923647932133,\n",
              "   0.621633085896077,\n",
              "   0.6483563096500541,\n",
              "   0.6335100742311777],\n",
              "  0.5558430540827157,\n",
              "  0.40959849499983714,\n",
              "  0.7020876131655943]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5JxSRnA39ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4d33532f-6bdd-4de0-a181-bd09539a3eee"
      },
      "source": [
        "#user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
        "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
        "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
        "\n",
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [item_cosine_recsys, \n",
        "                       user_cosine_recsys]\n",
        "\n",
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "cv_rmse = CrossValidation('RMSE')\n",
        "\n",
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "\n",
        "results = cv_rmse.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2102.48it/s]\n",
            "20000it [00:09, 2088.25it/s]\n",
            "20000it [00:09, 2091.61it/s]\n",
            "20000it [00:09, 2072.58it/s]\n",
            "20000it [00:09, 2122.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2142.64it/s]\n",
            "20000it [00:09, 2121.64it/s]\n",
            "20000it [00:09, 2129.17it/s]\n",
            "20000it [00:09, 2078.10it/s]\n",
            "20000it [00:09, 2115.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCttL7geQ_qA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c24687e2-e381-49d5-a499-67eed3019f3c"
      },
      "source": [
        "print('user-user RMSE average: ', results.get('user-cosine')[1])\n",
        "print('user-user RMSE confidence interval: (',results.get('user-cosine')[2], ',',results.get('user-cosine')[3],')')\n",
        "\n",
        "print('item-item RMSE average: ', results.get('item-cosine')[1])\n",
        "print('item-item RMSE confidence interval: (',results.get('item-cosine')[2], ',',results.get('item-cosine')[3],')')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user-user RMSE average:  1.017354121469863\n",
            "user-user RMSE confidence interval: ( 1.0090130800118484 , 1.0256951629278774 )\n",
            "item-item RMSE average:  1.020082900106248\n",
            "item-item RMSE confidence interval: ( 1.0068242686250732 , 1.0333415315874226 )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZH7FSvKcj3r",
        "colab_type": "text"
      },
      "source": [
        "Q3(b) User-user performed better. We have 943 users and 1682 items, so the user dimension is more dense than the item dimension. Thus the user-user similarity could be more accurate than item-item which can result in a better prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCFpLY25JuY",
        "colab_type": "text"
      },
      "source": [
        "## Q4 Probabilistic Matrix Factorization(PMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMdW5aLG5OTH",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1hS4CP5RVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "            \n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "            \n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "                \n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ########### your code goes here ###########\n",
        "    \n",
        "        self.w_Item = 0.1*np.random.randn(num_item, self.num_feat)  # item M x D \n",
        "        self.w_User = 0.1*np.random.randn(num_user,self.num_feat)  # user N x D \n",
        "    \n",
        "    \n",
        "        ###########         end         ###########  \n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########            \n",
        "                \n",
        "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :],self.w_Item[batch_ItemID, :]),axis = 1) #size (batch_size, )            \n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx, :],self.w_Item[train_item_idx, :]), axis = 1) # size(pairs_train, )      \n",
        " \n",
        "\n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx, :],self.w_Item[val_item_idx, :]), axis = 1) #size(pairs_val, )\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None \n",
        "            self.w_User = None \n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce7wlxycY76k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 17, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':False}) # maxepoch for rest q's = 17 originally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p56cFny7Y_Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "21904b91-8144-45dd-8ad8-a530793577e9"
      },
      "source": [
        "pmf.predict_all(rating_df, num_users, num_items)\n",
        "pmf.plot_error()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0yvmd21U3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkSLeDqzdu1",
        "colab_type": "text"
      },
      "source": [
        "## Q5 Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00OSiRl9zdu2",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ELkHEYgKgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c5eb868-ea2d-4a41-85c4-badfae6bc4c2"
      },
      "source": [
        "algorithm_instances = [popularity_recsys, \n",
        "                       average_user_rating_recsys, \n",
        "                       user_cosine_recsys, \n",
        "                       item_cosine_recsys, \n",
        "                       pmf]\n",
        "\n",
        "#algorithm_instances = [user_cosine_recsys, \n",
        "#                       pmf]\n",
        "\n",
        "evl_metrics = ['RMSE','P@K','R@K']\n",
        "\n",
        "instance_list = ['popularity', \n",
        "                 'useraverage', \n",
        "                 'user-cosine',\n",
        "                 'item-cosine',\n",
        "                 'PMF']\n",
        "results = []\n",
        "for evl in evl_metrics: \n",
        "  cv = CrossValidation(evl)\n",
        "  results.append(cv.run(algorithm_instances, num_users, num_items,k=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2020.89it/s]\n",
            "20000it [00:09, 2093.76it/s]\n",
            "20000it [00:09, 2124.97it/s]\n",
            "20000it [00:09, 2062.71it/s]\n",
            "20000it [00:09, 2084.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2118.53it/s]\n",
            "20000it [00:09, 2016.70it/s]\n",
            "20000it [00:09, 2120.99it/s]\n",
            "20000it [00:09, 2149.05it/s]\n",
            "20000it [00:09, 2156.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2098.14it/s]\n",
            "20000it [00:09, 2113.20it/s]\n",
            "20000it [00:09, 2054.33it/s]\n",
            "20000it [00:09, 2115.27it/s]\n",
            "20000it [00:09, 2134.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2024.15it/s]\n",
            "20000it [00:09, 2118.32it/s]\n",
            "20000it [00:09, 2088.10it/s]\n",
            "20000it [00:09, 2091.13it/s]\n",
            "20000it [00:09, 2116.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:16, 1177.74it/s]\n",
            "20000it [00:16, 1207.00it/s]\n",
            "20000it [00:16, 1189.20it/s]\n",
            "20000it [00:17, 1159.38it/s]\n",
            "20000it [00:16, 1190.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2136.74it/s]\n",
            "20000it [00:09, 2090.91it/s]\n",
            "20000it [00:09, 2154.59it/s]\n",
            "20000it [00:09, 2140.53it/s]\n",
            "20000it [00:09, 2172.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2159.89it/s]\n",
            "20000it [00:09, 2157.50it/s]\n",
            "20000it [00:09, 2147.05it/s]\n",
            "20000it [00:09, 2160.49it/s]\n",
            "20000it [00:09, 2097.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2146.47it/s]\n",
            "20000it [00:09, 2116.20it/s]\n",
            "20000it [00:09, 2117.33it/s]\n",
            "20000it [00:09, 2089.14it/s]\n",
            "20000it [00:09, 2133.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2134.61it/s]\n",
            "20000it [00:09, 2138.01it/s]\n",
            "20000it [00:09, 2091.04it/s]\n",
            "20000it [00:09, 2102.20it/s]\n",
            "20000it [00:09, 2110.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:16, 1193.31it/s]\n",
            "20000it [00:16, 1182.70it/s]\n",
            "20000it [00:16, 1231.43it/s]\n",
            "20000it [00:16, 1226.65it/s]\n",
            "20000it [00:16, 1223.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2105.67it/s]\n",
            "20000it [00:09, 2105.05it/s]\n",
            "20000it [00:09, 2102.79it/s]\n",
            "20000it [00:09, 2047.50it/s]\n",
            "20000it [00:09, 2079.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2160.39it/s]\n",
            "20000it [00:09, 2136.89it/s]\n",
            "20000it [00:09, 2147.13it/s]\n",
            "20000it [00:09, 2028.66it/s]\n",
            "20000it [00:09, 2138.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2140.04it/s]\n",
            "20000it [00:09, 2176.01it/s]\n",
            "20000it [00:09, 2142.86it/s]\n",
            "20000it [00:09, 2157.47it/s]\n",
            "20000it [00:09, 2151.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2080.27it/s]\n",
            "20000it [00:09, 2098.64it/s]\n",
            "20000it [00:09, 2114.12it/s]\n",
            "20000it [00:10, 1965.53it/s]\n",
            "20000it [00:09, 2096.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:16, 1184.08it/s]\n",
            "20000it [00:17, 1169.25it/s]\n",
            "20000it [00:16, 1180.01it/s]\n",
            "20000it [00:16, 1194.64it/s]\n",
            "20000it [00:16, 1210.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uh79B0nn5ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "33d54a2c-a0d4-4ff8-f591-02cb709c573e"
      },
      "source": [
        "#for i in range(3): \n",
        "  #for ins, res in results[i].items():\n",
        "    #print('average of ', evl_metrics[i], ' for ', ins, ' is ', res[1])\n",
        "    #print('confidence interval of ', evl_metrics[i], ' for ', ins, ' is (', res[2], ',', res[3], ')')\n",
        "\n",
        "for i in range(3): \n",
        "  print(evl_metrics[i],\":\")\n",
        "  for ins, res in results[i].items(): \n",
        "    print(ins, ' average: ', res[1])\n",
        "    print(ins, ' confidence interval: ', '(', res[2], ',', res[3], ')')\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :\n",
            "popularity  average:  3.1590928909890112\n",
            "popularity  confidence interval:  ( 3.139292746995387 , 3.1788930349826354 )\n",
            "useraverage  average:  1.0437176561595025\n",
            "useraverage  confidence interval:  ( 1.0289303496379316 , 1.0585049626810734 )\n",
            "user-cosine  average:  1.017354121469863\n",
            "user-cosine  confidence interval:  ( 1.0090130800118484 , 1.0256951629278774 )\n",
            "item-cosine  average:  1.020082900106248\n",
            "item-cosine  confidence interval:  ( 1.0068242686250732 , 1.0333415315874226 )\n",
            "PMF  average:  0.9429437612536613\n",
            "PMF  confidence interval:  ( 0.9266472856027127 , 0.9592402369046099 )\n",
            "\n",
            "\n",
            "P@K :\n",
            "popularity  average:  0.5505832449628855\n",
            "popularity  confidence interval:  ( 0.40544114481568705 , 0.6957253451100839 )\n",
            "useraverage  average:  0.4736373276776259\n",
            "useraverage  confidence interval:  ( 0.3419993013451059 , 0.6052753540101459 )\n",
            "user-cosine  average:  0.5558430540827157\n",
            "user-cosine  confidence interval:  ( 0.40959849499983714 , 0.7020876131655943 )\n",
            "item-cosine  average:  0.5322163308589621\n",
            "item-cosine  confidence interval:  ( 0.3837005215009889 , 0.6807321402169354 )\n",
            "PMF  average:  0.5552492046659606\n",
            "PMF  confidence interval:  ( 0.40963020170531383 , 0.7008682076266074 )\n",
            "\n",
            "\n",
            "R@K :\n",
            "popularity  average:  0.4840758878843688\n",
            "popularity  confidence interval:  ( 0.3671373629798323 , 0.6010144127889052 )\n",
            "useraverage  average:  0.44132320502242983\n",
            "useraverage  confidence interval:  ( 0.32931026359142457 , 0.5533361464534351 )\n",
            "user-cosine  average:  0.4862687235536437\n",
            "user-cosine  confidence interval:  ( 0.3694473610987218 , 0.6030900860085656 )\n",
            "item-cosine  average:  0.4749711148590666\n",
            "item-cosine  confidence interval:  ( 0.35357317503649865 , 0.5963690546816346 )\n",
            "PMF  average:  0.4858116210678999\n",
            "PMF  confidence interval:  ( 0.36928230490358993 , 0.6023409372322098 )\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ndWFEgUzdu4",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTBXTv6tzdu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNWRcTEl6HM",
        "colab_type": "text"
      },
      "source": [
        "Q5 (b)\n",
        "\n",
        "Popularity cannot be evaluated by RMSE. It could be because the popularity is calculated by the percentage of users who rated the movie above 4 out of all users who rated the item, and there is no numerical accuracy for such percentage. The scale is different, popularity is [0,1] whereas the actual rating is [1,5]. \n",
        "\n",
        "Alternatively, I think user average and popularity cannot be evaluated with P@k and R@k either. Because these two are ranking metrics, but user average and popularity do not actually have ranking. \n",
        "\n",
        "Q5 (c)\n",
        "\n",
        "Best for RMSE: PMF;\n",
        "\n",
        "PMF is best for the RMSE because it has an explicit objective function to optimize and the rating matrix is very large and sparse. \n",
        "\n",
        "Best for P@k: user-cosine; \n",
        "\n",
        "\n",
        "Best for R@k: user-cosine;  \n",
        "\n",
        "User-cosine is better than PMF in P@k and R@k because the objective function that PMF explicitly optimizes is the squared errer not the P@k or R@k. User-cosine performs the best because the user dimension in the rating matrix is relatively more dense than the item dimension. Thus the user similarity score could be more reliable than others and gives better prediction. \n",
        "\n",
        "\n",
        "Q5 (d)\n",
        "Good performance on RMSE implies good performance on ranking but not neccessarily vice versa. Because in recommender system, rating numerically accurate is not important, what the user needs is ranked results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkx8GW4wzdu8",
        "colab_type": "text"
      },
      "source": [
        "## Q6 Similarity Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnLcDctYzdu9",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16agjyHzdu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getItemData(folder_path, file_name):\n",
        "  \n",
        "    #http://files.grouplens.org/datasets/movielens/ml-100k/u.item\n",
        "    fields = ['movieId', 'movieTitle', 'releaseDate', 'videoReleaseDate', \n",
        "              'IMDbURL',  'unknown', 'Action',  'Adventure',  'Animation', \n",
        "              'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \n",
        "              'Film-Noir', 'Horror', 'Musical',  'Mystery', 'Romance', 'Sci-Fi',\n",
        "              'Thriller', 'War', 'Western']\n",
        "    \n",
        "    # Reference: https://stackoverflow.com/questions/5552555/unicodedecodeerror-invalid-continuation-byte\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='|', names=fields,encoding='latin-1')\n",
        "    return data \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB1PXGHwfons",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies_df = getItemData(MOVIELENS_DIR, 'u.item')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jBlKamygmq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainMatrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "ii_similarity = SimBasedRecSys.cosine(trainMatrix.transpose())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRlOi6ei8vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top5Similar(ii_similarity, movie_name, movie_ID):\n",
        "  # Referemces: https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array\n",
        "  # https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order\n",
        "  similarity = ii_similarity[movie_ID-1]\n",
        "  index = similarity.argsort()[::-1][1:6]\n",
        "  \n",
        "  # Ref: https://www.geeksforgeeks.org/python-map-function/\n",
        "  # syntax: map(fun, iter), apply fun to each item in iter\n",
        "  result = map(lambda x: movies_df[movies_df.movieId ==x+1]['movieTitle'].values[0],index)\n",
        "  \n",
        "  top5sim = list(result)\n",
        "  \n",
        "  print('The top 5 most similar movies of ', movie_name, 'are: \\n', top5sim)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQvgbjhnLXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b85d7257-9b72-478a-cf7e-6d5bd060934d"
      },
      "source": [
        "top5Similar(ii_similarity, 'Snow White and the Seven Dwarfs',99)\n",
        "top5Similar(ii_similarity, 'Batman Forever', 29)\n",
        "top5Similar(ii_similarity, 'Sleepless in Seattle', 88)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 5 most similar movies of  Snow White and the Seven Dwarfs are: \n",
            " ['Beauty and the Beast (1991)', 'Cinderella (1950)', 'Pinocchio (1940)', 'Fantasia (1940)', 'Dumbo (1941)']\n",
            "The top 5 most similar movies of  Batman Forever are: \n",
            " ['Batman (1989)', 'Batman Returns (1992)', 'Cliffhanger (1993)', 'Demolition Man (1993)', 'Stargate (1994)']\n",
            "The top 5 most similar movies of  Sleepless in Seattle are: \n",
            " ['While You Were Sleeping (1995)', 'Mrs. Doubtfire (1993)', 'Groundhog Day (1993)', 'When Harry Met Sally... (1989)', 'Dave (1993)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnRDOuH4zdvF",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVP7KMEtrLqg",
        "colab_type": "text"
      },
      "source": [
        "For most cases, the top 5 similar either fall into the same genres as the picked one or content-wise they are similar.  \n",
        "\n",
        "\n",
        "'Snow White and the Seven Dwarfs' is animation, children's and musical, so are the 'Beauty and the Beast' and 'Cinderella', whereas 'Pinocchio' and 'Fantasia' are not musical but still animation and children's. However, 'Dumbo' has the exactly same genres as 'Snow Whie and the Seven Dwarfs', but it is just at top 5, I think the reason could be that the content of 'Dumbo' is not very similar to the Snow White, thus the users did not tend to rate them the same. Overall, they are Disney movies, users prefer one of them would be very likely to watch others and have similar satisfaction levels for them. \n",
        "\n",
        "\n",
        "For 'Batman Forever', the top two 'Batman' and 'Batman Returns' are the same serie of movies, thus users who are fans of Batman tend to watch them all and provide similar ratings. For 'Cliffhanger', it's in the same genres as 'Batman Forever' except it's not a comedy. 'Demolition Man' is action and sci-fi, only one overlap in genre as 'Batman Forever' (action), which I don't think it's so similar as the Batman movie. 'Stargate' has two overlaps in genre (action and adventure), but also two variations. But on the other hand, I think 'Batman Forever' is also a fantasy movie (and probably sci-fi), so that also makes sense to categorize the last three movies in top 5 as very similar to it as users may like that specific type of movies. \n",
        "\n",
        "\n",
        "'Sleepless in Seattle is a romantic movie telling how two people fall in love with each other just through listening to a radio program. In the top 5, 4 of them have exactly the same genres as 'Sleepless in Seattle', comedy and romance. The one exception is 'Mrs. Doubtfire', but for the content-wise, it is still similar to the picked one, family issue, meet someone and life changes etc. Categorizing them as similar items make sense since users are vely likely to watching most of them and providing similar ratings (i.e. have a constant tast over movies). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-53EKu7zdvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiSiG2UrzdvK",
        "colab_type": "text"
      },
      "source": [
        "## Q7 Testing with different user types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH63iq22zdvK",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeUK2ZR5zdvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6aa833be-ac03-48bb-fc54-7571cad4fbf1"
      },
      "source": [
        "temp_matrix = np.zeros(trainMatrix.shape)\n",
        "temp_matrix[trainMatrix.nonzero()] = 1\n",
        "num_items_rated = np.sum(temp_matrix, axis=1)\n",
        "\n",
        "#print(trainMatrix.shape)\n",
        "#print(num_items_rated)\n",
        "\n",
        "plt.hist(num_items_rated, bins = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATB0lEQVR4nO3df4ydV33n8fdn7fxggY3zYzZybbMO\nbVqUrrZONJsGgSo2EW1iKkwlihJVxUJZubsbJBDVtk5X2hZpI4XVlrRIu+m6TYpZAUk2wMYK6bZp\nElRRiYRJcEJ+kGUAo9hy4gGSAIsabcJ3/7jHyY0Ze+7MnRnfObxf0tWc55zz3PudufZnnjn3ufdJ\nVSFJ6ss/OtkFSJKWn+EuSR0y3CWpQ4a7JHXIcJekDq0/2QUAnHPOObV169aTXYYkrSkPPvjgd6pq\nar6xiQj3rVu3MjMzc7LLkKQ1Jcm3jzfmsowkdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y\n3CWpQ4a7JHVoIt6hOo6tuz8/1v4Hrn/HMlUiSZPDI3dJ6pDhLkkdMtwlqUOGuyR1aORwT7IuyVeS\n3Nm2z0tyf5LZJLcmObX1n9a2Z9v41pUpXZJ0PIs5cv8A8MTQ9keAG6rq54Bngatb/9XAs63/hjZP\nkrSKRgr3JJuBdwB/0bYDXArc3qbsBd7V2jvaNm38sjZfkrRKRj1y/xPg94Aft+2zgeeq6sW2fRDY\n1NqbgKcA2vjzbf6rJNmVZCbJzNzc3BLLlyTNZ8FwT/LrwJGqenA5H7iq9lTVdFVNT03NewlASdIS\njfIO1bcA70yyHTgd+CfAnwIbkqxvR+ebgUNt/iFgC3AwyXrgDOC7y165JOm4Fjxyr6prq2pzVW0F\nrgTurarfAu4D3t2m7QTuaO19bZs2fm9V1bJWLUk6oXHOc/994ENJZhmsqd/U+m8Czm79HwJ2j1ei\nJGmxFvXBYVX1BeALrf1N4OJ55vwD8JvLUJskaYl8h6okdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq\nkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdGuUaqqcneSDJw0keS/Lh\n1v/xJN9Ksr/dtrX+JPlYktkkjyS5aKW/CUnSq41ysY4XgEur6odJTgG+mOSv2ti/r6rbj5l/BXB+\nu/0ycGP7KklaJaNcQ7Wq6odt85R2O9E1UXcAn2j7fYnBhbQ3jl+qJGlUI625J1mXZD9wBLi7qu5v\nQ9e1pZcbkpzW+jYBTw3tfrD1SZJWyUjhXlUvVdU2YDNwcZJ/DlwLvAn4l8BZDC6YPbIku5LMJJmZ\nm5tbZNmSpBNZ1NkyVfUccB9weVUdbksvLwB/ySsXyz4EbBnabXPrO/a+9lTVdFVNT01NLa16SdK8\nRjlbZirJhtZ+DfB24GtH19GTBHgX8GjbZR/w3nbWzCXA81V1eEWqlyTNa5SzZTYCe5OsY/DL4Laq\nujPJvUmmgAD7gX/T5t8FbAdmgR8B71v+siVJJ7JguFfVI8CF8/Rfepz5BVwzfmmSpKXyHaqS1CHD\nXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwl\nqUOGuyR1yHCXpA6Ncpm905M8kOThJI8l+XDrPy/J/Ulmk9ya5NTWf1rbnm3jW1f2W5AkHWuUI/cX\ngEur6peAbcDl7dqoHwFuqKqfA54Frm7zrwaebf03tHmSpFW0YLjXwA/b5intVsClwO2tfy+Di2QD\n7GjbtPHL2kW0JUmrZKQ19yTrkuwHjgB3A98AnquqF9uUg8Cm1t4EPAXQxp8Hzp7nPnclmUkyMzc3\nN953IUl6lZHCvapeqqptwGbgYuBN4z5wVe2pqumqmp6amhr37iRJQxZ1tkxVPQfcB7wZ2JBkfRva\nDBxq7UPAFoA2fgbw3WWpVpI0klHOlplKsqG1XwO8HXiCQci/u03bCdzR2vvaNm383qqq5SxaknRi\n6xeewkZgb5J1DH4Z3FZVdyZ5HLglyX8CvgLc1ObfBPyPJLPA94ArV6BuSdIJLBjuVfUIcOE8/d9k\nsP5+bP8/AL+5LNVJkpbEd6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH\nDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjo0ymX2tiS5L8njSR5L8oHW/0dJDiXZ327b\nh/a5NslskieT/NpKfgOSpJ80ymX2XgR+t6oeSvJ64MEkd7exG6rqvwxPTnIBg0vr/SLwM8DfJvn5\nqnppOQuXJB3fgkfuVXW4qh5q7R8wuDj2phPssgO4papeqKpvAbPMczk+SdLKWdSae5KtDK6nen/r\nen+SR5LcnOTM1rcJeGpot4PM88sgya4kM0lm5ubmFl24JOn4Rg73JK8DPgN8sKq+D9wI/CywDTgM\n/PFiHriq9lTVdFVNT01NLWZXSdICRgr3JKcwCPZPVtVnAarqmap6qap+DPw5ryy9HAK2DO2+ufVJ\nklbJKGfLBLgJeKKqPjrUv3Fo2m8Aj7b2PuDKJKclOQ84H3hg+UqWJC1klLNl3gL8NvDVJPtb3x8A\nVyXZBhRwAPgdgKp6LMltwOMMzrS5xjNlJGl1LRjuVfVFIPMM3XWCfa4DrhujLknSGHyHqiR1yHCX\npA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq\nkOEuSR0y3CWpQ6NcZm9LkvuSPJ7ksSQfaP1nJbk7ydfb1zNbf5J8LMlskkeSXLTS34Qk6dVGOXJ/\nEfjdqroAuAS4JskFwG7gnqo6H7inbQNcweC6qecDu4Abl71qSdIJLRjuVXW4qh5q7R8ATwCbgB3A\n3jZtL/Cu1t4BfKIGvgRsOOZi2pKkFbaoNfckW4ELgfuBc6vqcBt6Gji3tTcBTw3tdrD1HXtfu5LM\nJJmZm5tbZNmSpBMZOdyTvA74DPDBqvr+8FhVFVCLeeCq2lNV01U1PTU1tZhdJUkLGCnck5zCINg/\nWVWfbd3PHF1uaV+PtP5DwJah3Te3PknSKhnlbJkANwFPVNVHh4b2ATtbeydwx1D/e9tZM5cAzw8t\n30iSVsH6Eea8Bfht4KtJ9re+PwCuB25LcjXwbeA9bewuYDswC/wIeN+yVixJWtCC4V5VXwRynOHL\n5plfwDVj1iVJGoPvUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLU\nIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWiUy+zdnORIkkeH+v4oyaEk+9tt+9DYtUlmkzyZ\n5NdWqnBJ0vGNcuT+ceDyefpvqKpt7XYXQJILgCuBX2z7/Lck65arWEnSaBYM96r6O+B7I97fDuCW\nqnqhqr7F4DqqF49RnyRpCcZZc39/kkfass2ZrW8T8NTQnIOt7yck2ZVkJsnM3NzcGGVIko611HC/\nEfhZYBtwGPjjxd5BVe2pqumqmp6amlpiGZKk+Swp3Kvqmap6qap+DPw5ryy9HAK2DE3d3PokSato\n/VJ2SrKxqg63zd8Ajp5Jsw/4VJKPAj8DnA88MHaVK2jr7s8ved8D179jGSuRpOWzYLgn+TTwNuCc\nJAeBPwTelmQbUMAB4HcAquqxJLcBjwMvAtdU1UsrU7ok6XgWDPequmqe7ptOMP864LpxipIkjcd3\nqEpShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7\nJHXIcJekDhnuktQhw12SOrRguCe5OcmRJI8O9Z2V5O4kX29fz2z9SfKxJLNJHkly0UoWL0ma3yhH\n7h8HLj+mbzdwT1WdD9zTtgGuYHDd1POBXcCNy1OmJGkxFgz3qvo74HvHdO8A9rb2XuBdQ/2fqIEv\nARuSbFyuYiVJo1nwGqrHcW5VHW7tp4FzW3sT8NTQvIOt7zDHSLKLwdE9b3jDG5ZYxsm1dffnl7zv\ngevfsYyVSNKrjf2CalUVUEvYb09VTVfV9NTU1LhlSJKGLDXcnzm63NK+Hmn9h4AtQ/M2tz5J0ipa\narjvA3a29k7gjqH+97azZi4Bnh9avpEkrZIF19yTfBp4G3BOkoPAHwLXA7cluRr4NvCeNv0uYDsw\nC/wIeN8K1CxJWsCC4V5VVx1n6LJ55hZwzbhFSZLG4ztUJalDhrskdWip57lrTJ4jL2kleeQuSR0y\n3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUobE+\nFTLJAeAHwEvAi1U1neQs4FZgK3AAeE9VPTtemZKkxViOI/d/VVXbqmq6be8G7qmq84F72rYkaRWt\nxOe572BwzVWAvcAXgN9fgcf5qTXOZ8GDnwcv/TQY98i9gL9J8mCSXa3v3Ko63NpPA+fOt2OSXUlm\nkszMzc2NWYYkadi4R+5vrapDSf4pcHeSrw0PVlUlqfl2rKo9wB6A6enpeedIkpZmrHCvqkPt65Ek\nnwMuBp5JsrGqDifZCBxZhjq1jLzEn9S/JS/LJHltktcfbQO/CjwK7AN2tmk7gTvGLVKStDjjHLmf\nC3wuydH7+VRV/e8kXwZuS3I18G3gPeOXKUlajCWHe1V9E/ilefq/C1w2TlGSpPH4DlVJ6pDhLkkd\nMtwlqUOGuyR1aCU+fkCal+fXS6vHI3dJ6pBH7lqUcT+0TNLq8MhdkjpkuEtShwx3SeqQ4S5JHfIF\nVa0JnkYpLY5H7pLUIY/cpQX4V4PWIsNd3fPcfP00cllGkjq0YuGe5PIkTyaZTbJ7pR5HkvSTVmRZ\nJsk64L8CbwcOAl9Osq+qHl+Jx5Mm1clar/d1Aq3UmvvFwGy7FB9JbgF2AIa7NKKT9VrBuI97sn45\nrNXXVlbq57VS4b4JeGpo+yDwy8MTkuwCdrXNHyZ58jj3dQ7wnWWvcPmtlTph7dS6VuqEtVPriteZ\njyzbXf1U/EzH/Hn9s+MNnLSzZapqD7BnoXlJZqpqehVKGstaqRPWTq1rpU5YO7WulTph7dQ6qXWu\n1Auqh4AtQ9ubW58kaRWsVLh/GTg/yXlJTgWuBPat0GNJko6xIssyVfVikvcDfw2sA26uqseWeHcL\nLt1MiLVSJ6ydWtdKnbB2al0rdcLaqXUi60xVnewaJEnLzHeoSlKHDHdJ6tDEhvukfXxBkpuTHEny\n6FDfWUnuTvL19vXM1p8kH2u1P5LkolWsc0uS+5I8nuSxJB+Y4FpPT/JAkodbrR9u/eclub/VdGt7\nUZ4kp7Xt2Ta+dbVqbY+/LslXktw54XUeSPLVJPuTzLS+SXz+NyS5PcnXkjyR5M2TVmeSX2g/x6O3\n7yf54KTVOa+qmrgbgxdhvwG8ETgVeBi44CTX9CvARcCjQ33/Gdjd2ruBj7T2duCvgACXAPevYp0b\ngYta+/XA/wEumNBaA7yutU8B7m813AZc2fr/DPi3rf3vgD9r7SuBW1f538CHgE8Bd7btSa3zAHDO\nMX2T+PzvBf51a58KbJjEOofqXQc8zeCNQxNb58v1nqwHXuCH+Gbgr4e2rwWunYC6th4T7k8CG1t7\nI/Bka/934Kr55p2Emu9g8Bk/E10r8I+Bhxi8k/k7wPpj/y0wOPvqza29vs3LKtW3GbgHuBS4s/3n\nnbg622POF+4T9fwDZwDfOvbnMml1HlPbrwJ/P+l1Hr1N6rLMfB9fsOkk1XIi51bV4dZ+Gji3tSei\n/rYccCGDI+KJrLUtdewHjgB3M/iL7bmqenGeel6utY0/D5y9SqX+CfB7wI/b9tkTWidAAX+T5MEM\nPuYDJu/5Pw+YA/6yLXX9RZLXTmCdw64EPt3ak1wnMMFr7mtNDX5NT8x5pUleB3wG+GBVfX94bJJq\nraqXqmobgyPji4E3neSSfkKSXweOVNWDJ7uWEb21qi4CrgCuSfIrw4MT8vyvZ7DMeWNVXQj8XwbL\nGy+bkDoBaK+nvBP4n8eOTVKdwyY13NfKxxc8k2QjQPt6pPWf1PqTnMIg2D9ZVZ+d5FqPqqrngPsY\nLG9sSHL0DXbD9bxcaxs/A/juKpT3FuCdSQ4AtzBYmvnTCawTgKo61L4eAT7H4JfmpD3/B4GDVXV/\n276dQdhPWp1HXQE8VFXPtO1JrfNlkxrua+XjC/YBO1t7J4P17aP9722vnF8CPD/0J9yKShLgJuCJ\nqvrohNc6lWRDa7+GwWsDTzAI+Xcfp9aj38O7gXvbUdOKqqprq2pzVW1l8G/x3qr6rUmrEyDJa5O8\n/mibwTrxo0zY819VTwNPJfmF1nUZg48En6g6h1zFK0syR+uZxDpfcTIW+kd88WI7gzM9vgH8hwmo\n59PAYeD/MTjquJrBOuo9wNeBvwXOanPD4GIl3wC+CkyvYp1vZfAn4iPA/nbbPqG1/gvgK63WR4H/\n2PrfCDwAzDL4M/i01n96255t4288Cf8O3sYrZ8tMXJ2tpofb7bGj/3cm9PnfBsy05/9/AWdOaJ2v\nZfCX1xlDfRNX57E3P35Akjo0qcsykqQxGO6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ/8fzPC0\nblNlJj4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6bgTcHivtmb",
        "colab_type": "text"
      },
      "source": [
        "The threshold tau is 60. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XAE4e5sFJuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_with_threshold(train_matrix, base):\n",
        "        \n",
        "        if base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "             # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
        "            \n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            # UxU mul UxI = UxI\n",
        "            \n",
        "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "            #print(predictionMatrix)\n",
        "            \n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average\n",
        "            \n",
        "            ### ??? + 1e-5 or not??\n",
        "            useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1)+1e-5)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            \n",
        "            return predictionMatrix\n",
        "          \n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "            # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = 1 - pairwise_distances(train_matrix.transpose(), metric='cosine')\n",
        "            \n",
        "            # IxU: IxI mul IxU\n",
        "            normalizer = np.matmul(ii_similarity, temp_matrix.transpose())\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            \n",
        "            # IxI mul IxU\n",
        "            predictionMatrix = np.matmul(ii_similarity, train_matrix.transpose())/normalizer\n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use item average\n",
        "            \n",
        "            ### ??? + 1e-5 or not?? \n",
        "            itemaverage = np.sum(train_matrix.transpose(), axis=1)/(np.sum(temp_matrix.transpose(), axis=1) +1e-5)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            #print(columns.shape)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "            \n",
        "            return predictionMatrix.transpose()\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alDZhJv1RV2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tau = 60\n",
        "\n",
        "u1_base_df = getData(MOVIELENS_DIR, 'u1.base')\n",
        "u1_test_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "\n",
        "u2_base_df = getData(MOVIELENS_DIR, 'u2.base')\n",
        "u2_test_df = getData(MOVIELENS_DIR, 'u2.test')\n",
        "\n",
        "u3_base_df = getData(MOVIELENS_DIR, 'u3.base')\n",
        "u3_test_df = getData(MOVIELENS_DIR, 'u3.test')\n",
        "\n",
        "u4_base_df = getData(MOVIELENS_DIR, 'u4.base')\n",
        "u4_test_df = getData(MOVIELENS_DIR, 'u4.test')\n",
        "\n",
        "u5_base_df = getData(MOVIELENS_DIR, 'u5.base')\n",
        "u5_test_df = getData(MOVIELENS_DIR, 'u5.test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXDI2DmAXVke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9ad0807e-a365-49c5-aba9-ab8e12617dc9"
      },
      "source": [
        "base_list = [u1_base_df,u2_base_df,u3_base_df,u4_base_df,u5_base_df]\n",
        "\n",
        "test_list = [u1_test_df,u2_test_df,u3_test_df,u4_test_df,u5_test_df]\n",
        "\n",
        "# Ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
        "\n",
        "# count the number of ratings per user, group by users and drop the other two columns\n",
        "\n",
        "count_ratings = rating_df.groupby('userID').count().reset_index()\n",
        "count_ratings.drop('itemID',axis=1,inplace=True)\n",
        "count_ratings.drop('timestamp',axis=1,inplace=True)\n",
        "\n",
        "count_ratings # used for split the dataframe by threshold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     userID  rating\n",
              "0         1     272\n",
              "1         2      62\n",
              "2         3      54\n",
              "3         4      24\n",
              "4         5     175\n",
              "..      ...     ...\n",
              "938     939      49\n",
              "939     940     107\n",
              "940     941      22\n",
              "941     942      79\n",
              "942     943     168\n",
              "\n",
              "[943 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxOpaSzfiyyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_above_threshold(count_ratings, df, threshold): \n",
        "  df_above = df[df['userID'].isin(count_ratings[count_ratings['rating']>=threshold]['userID'].tolist())]  \n",
        "  return df_above\n",
        "\n",
        "def split_below_threshold(count_ratings, df, threshold): \n",
        "  df_below = df[df['userID'].isin(count_ratings[count_ratings['rating']<threshold]['userID'].tolist())]  \n",
        "  return df_below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IKbn9b_gQL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_list = [u1_base_df, u2_base_df,u3_base_df, u4_base_df, u5_base_df]\n",
        "test_list = [u1_test_df, u2_test_df,u3_test_df, u4_test_df, u5_test_df]\n",
        "\n",
        "split_base_above = []\n",
        "split_test_above = []\n",
        "split_base_below = []\n",
        "split_test_below = []\n",
        "\n",
        "for ds in base_list: \n",
        "  split_base_above.append(split_above_threshold(count_ratings,ds,tau))\n",
        "  split_base_below.append(split_below_threshold(count_ratings,ds,tau))\n",
        "\n",
        "for ds in test_list: \n",
        "  split_test_above.append(split_above_threshold(count_ratings,ds,tau))\n",
        "  split_test_below.append(split_below_threshold(count_ratings,ds,tau))\n",
        "\n",
        "base_above_matrix = []\n",
        "base_below_matrix = []\n",
        "test_above_matrix = []\n",
        "test_below_matrix = []\n",
        "\n",
        "for ds in split_base_above: \n",
        "   base_above_matrix.append(dataPreprocessor(ds, num_users, num_items))\n",
        "\n",
        "for ds in split_base_below: \n",
        "   base_below_matrix.append(dataPreprocessor(ds, num_users, num_items))\n",
        "\n",
        "for ds in split_test_above: \n",
        "   test_above_matrix.append(dataPreprocessor(ds, num_users, num_items))\n",
        "\n",
        "for ds in split_test_below: \n",
        "   test_below_matrix.append(dataPreprocessor(ds, num_users, num_items))\n",
        "\n",
        "# u.test is the ground truth  \n",
        "results_uu_above = []\n",
        "results_ii_above = []\n",
        "\n",
        "results_uu_below = []\n",
        "results_ii_below = []\n",
        "\n",
        "for ds in base_above_matrix: \n",
        "  results_uu_above.append(predict_with_threshold(ds, 'user'))\n",
        "  results_ii_above.append(predict_with_threshold(ds, 'item'))\n",
        "\n",
        "for ds in base_below_matrix: \n",
        "  results_uu_below.append(predict_with_threshold(ds, 'user'))\n",
        "  results_ii_below.append(predict_with_threshold(ds, 'item'))\n",
        "\n",
        "\n",
        "#for i in range(len(base_above_matrix)): \n",
        "  #print('base ', i, 'high ', base_above_matrix[i].shape)\n",
        "  #print('test ', i, 'high ', test_above_matrix[i].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAUV8iPqZQQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "12f8b437-4bc3-4887-e959-156b74ecb306"
      },
      "source": [
        "rmse_uu_above = []\n",
        "rmse_uu_below = []\n",
        "\n",
        "rmse_ii_above = []\n",
        "rmse_ii_below = []\n",
        "\n",
        "for k in range(5): \n",
        "  rmse_uu_above.append(sqrt(mean_squared_error(results_uu_above[k][test_above_matrix[k].nonzero()], test_above_matrix[k][test_above_matrix[k].nonzero()])))\n",
        "  rmse_uu_below.append(sqrt(mean_squared_error(results_uu_below[k][test_below_matrix[k].nonzero()], test_below_matrix[k][test_below_matrix[k].nonzero()])))\n",
        "  rmse_ii_above.append(sqrt(mean_squared_error(results_ii_above[k][test_above_matrix[k].nonzero()], test_above_matrix[k][test_above_matrix[k].nonzero()])))\n",
        "  rmse_ii_below.append(sqrt(mean_squared_error(results_ii_below[k][test_below_matrix[k].nonzero()], test_below_matrix[k][test_below_matrix[k].nonzero()])))\n",
        "\n",
        "print('user-user above threshold: ')\n",
        "for rs in rmse_uu_above: \n",
        "  print(rs)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('user-user below threshold: ')\n",
        "for rs in rmse_uu_below: \n",
        "  print(rs)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('iterm-item above threshold: ')\n",
        "for rs in rmse_ii_above: \n",
        "  print(rs)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('item-item below threshold: ')\n",
        "for rs in rmse_ii_below: \n",
        "  print(rs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user-user above threshold: \n",
            "1.0222508497989067\n",
            "1.0129894527257868\n",
            "1.0079215342494896\n",
            "1.0003440505046612\n",
            "1.0132621432259783\n",
            "\n",
            "\n",
            "user-user below threshold: \n",
            "1.0856180512843645\n",
            "1.1115796009153012\n",
            "1.0972227563443557\n",
            "1.0983263790977529\n",
            "1.1074091722054182\n",
            "\n",
            "\n",
            "iterm-item above threshold: \n",
            "1.0414573747283948\n",
            "1.0211881672744636\n",
            "1.0075002492090388\n",
            "1.0086623078722967\n",
            "1.0179643938821543\n",
            "\n",
            "\n",
            "item-item below threshold: \n",
            "1.1692417179982133\n",
            "1.154541859294865\n",
            "1.151801618051339\n",
            "1.161450598600089\n",
            "1.1297862711179716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm2IGp7_P06_",
        "colab_type": "text"
      },
      "source": [
        "For both user-user and item-item similarity, the rusults of above threshold are better (i.e. case(i) is better). Because when users have more rated items (the rating matix is more dense), the similarity scores between users and items are more reliable to make predictions (i.e. they are less likely to be affected by outliers). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G2V2BXb-zdvQ",
        "colab_type": "text"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjWEiRzezdvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZ3DOSHzdvV",
        "colab_type": "text"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4jypcIRzdvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Tc_IVazdvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_PmoIrWzdvf",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGA1yZ9hzdvf",
        "colab_type": "text"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ySapEazdvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyCJ1Be0zdvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validatePopularityRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1wwQpxzdvp",
        "colab_type": "text"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1KASm63zdvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A36VedIzdvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateUserAverRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlxJxooBzdvx",
        "colab_type": "text"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvmIFAXXzdvy",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74E1PMRzdvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqzEUppEzdv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateEuclidean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBQxFEPzdv6",
        "colab_type": "text"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpRR_hjzdv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uGIWOS7zdv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateCustomizedSim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMKOOB6mzdwB",
        "colab_type": "text"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_V0gdBTzdwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkausxHizdwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IAGUMvwzdwH",
        "colab_type": "text"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-j6pDB3zdwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjAlZnpYzdwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateIISimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYo97yYTCKbI",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Matrix Factorization Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB1_H8mxzdwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate PMFRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW82XMfdzdwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldve7N_0DRF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}